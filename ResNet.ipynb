{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aaa9d4b",
   "metadata": {},
   "source": [
    "## Deep Learning\n",
    "\n",
    "> Antonopoulos Ilias (p3352004) <br />\n",
    "> Ndoja Silva (p3352017) <br />\n",
    "> MSc Data Science AUEB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e6b51d",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Data Loading](#Data-Loading)\n",
    "- [Hyperparameter Tuning](#Hyperparameter-Tuning)\n",
    "- [Model Selection](#Model-Selection)\n",
    "- [Evaluation](#Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88eb046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-06 10:49:14.594955: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-06 10:49:14.594971: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140836a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96edda17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-06 10:49:21.636722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-06 10:49:21.637011: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-06 10:49:21.637053: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-06 10:49:21.637091: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-06 10:49:21.638432: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-06 10:49:21.638474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-03-06 10:49:21.638564: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c99bb4",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f57d2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d12d3533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3392e806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b594e776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "02ce3cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d0d3cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d990e8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c74d426",
   "metadata": {},
   "source": [
    "This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories,\n",
    "  along with a test set of 10,000 images.\n",
    "  \n",
    "The classes are:\n",
    "  \n",
    "| Label | Description |\n",
    "|:-----:|-------------|\n",
    "|   0   | T-shirt/top |\n",
    "|   1   | Trouser     |\n",
    "|   2   | Pullover    |\n",
    "|   3   | Dress       |\n",
    "|   4   | Coat        |\n",
    "|   5   | Sandal      |\n",
    "|   6   | Shirt       |\n",
    "|   7   | Sneaker     |\n",
    "|   8   | Bag         |\n",
    "|   9   | Ankle boot  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c6b81307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f6372",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "89e40239",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123456\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c8b10345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(model_):\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model_\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c60e87cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project hparam-tuning/resnet/oracle.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    kt.applications.HyperResNet(input_shape=(28, 28, 1), classes=10),\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=50,  # the maximum number of epochs to train one model\n",
    "    seed=SEED,\n",
    "    directory=\"hparam-tuning\",\n",
    "    project_name=\"resnet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1619ba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "version (Choice)\n",
      "{'default': 'v2', 'conditions': [], 'values': ['v1', 'v2', 'next'], 'ordered': False}\n",
      "conv3_depth (Choice)\n",
      "{'default': 4, 'conditions': [], 'values': [4, 8], 'ordered': True}\n",
      "conv4_depth (Choice)\n",
      "{'default': 6, 'conditions': [], 'values': [6, 23, 36], 'ordered': True}\n",
      "pooling (Choice)\n",
      "{'default': 'avg', 'conditions': [], 'values': ['avg', 'max'], 'ordered': False}\n",
      "optimizer (Choice)\n",
      "{'default': 'adam', 'conditions': [], 'values': ['adam', 'rmsprop', 'sgd'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.1, 0.01, 0.001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e80f13f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212219f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "version           |v2                |?                 \n",
      "conv3_depth       |8                 |?                 \n",
      "conv4_depth       |6                 |?                 \n",
      "pooling           |max               |?                 \n",
      "optimizer         |adam              |?                 \n",
      "learning_rate     |0.01              |?                 \n",
      "tuner/epochs      |2                 |?                 \n",
      "tuner/initial_e...|0                 |?                 \n",
      "tuner/bracket     |3                 |?                 \n",
      "tuner/round       |0                 |?                 \n",
      "\n",
      "Epoch 1/2\n",
      " 192/1500 [==>...........................] - ETA: 19:32 - loss: 2.2096 - accuracy: 0.4520"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    train_images, train_labels, epochs=50, validation_split=0.2, callbacks=[stop_early]\n",
    ")\n",
    "\n",
    "# get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bafa08",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f570c8b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cafa92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, to_file=\"static/resnet_model.png\", show_shapes=True, show_layer_names=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c1fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64aae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train_images, train_labels, epochs=30, validation_split=0.2)\n",
    "\n",
    "# keep best epoch\n",
    "val_acc_per_epoch = history.history[\"val_accuracy\"]\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print(\"Best epoch: %d\" % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a518431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# retrain the model\n",
    "history = hypermodel.fit(\n",
    "    train_images, train_labels, epochs=best_epoch, validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c234c695",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92200b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = hypermodel.evaluate(test_images, test_labels, verbose=3)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e268801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hs, epochs, metric):\n",
    "    print()\n",
    "    plt.style.use(\"dark_background\")\n",
    "    plt.rcParams[\"figure.figsize\"] = [15, 8]\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    plt.clf()\n",
    "    for label in hs:\n",
    "        plt.plot(\n",
    "            hs[label].history[metric],\n",
    "            label=\"{0:s} train {1:s}\".format(label, metric),\n",
    "            linewidth=2,\n",
    "        )\n",
    "        plt.plot(\n",
    "            hs[label].history[\"val_{0:s}\".format(metric)],\n",
    "            label=\"{0:s} validation {1:s}\".format(label, metric),\n",
    "            linewidth=2,\n",
    "        )\n",
    "    x_ticks = np.arange(0, epochs + 1, epochs / 10)\n",
    "    x_ticks[0] += 1\n",
    "    plt.xticks(x_ticks)\n",
    "    plt.ylim((0, 1))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\" if metric == \"loss\" else \"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c36b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Loss          : {0:.5f}\".format(history.history[\"loss\"][-1]))\n",
    "print(\"Validation Loss     : {0:.5f}\".format(history.history[\"val_loss\"][-1]))\n",
    "print(\"Test Loss           : {0:.5f}\".format(eval_result[0]))\n",
    "print(\"-------------------\")\n",
    "print(\"Train Accuracy      : {0:.5f}\".format(history.history[\"accuracy\"][-1]))\n",
    "print(\"Validation Accuracy : {0:.5f}\".format(history.history[\"val_accuracy\"][-1]))\n",
    "print(\"Test Accuracy       : {0:.5f}\".format(eval_result[1]))\n",
    "\n",
    "# Plot train and validation error per epoch.\n",
    "plot_history(hs={\"ResNet\": history}, epochs=best_epoch, metric=\"loss\")\n",
    "plot_history(hs={\"ResNet\": history}, epochs=best_epoch, metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6290d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    cm, classes, normalize=False, title=\"Confusion matrix\", cmap=plt.cm.PuBuGn\n",
    "):\n",
    "\n",
    "    plt.style.use(\"default\")\n",
    "    plt.rcParams[\"figure.figsize\"] = [11, 9]\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e56fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict the values from the validation dataset\n",
    "Y_pred = hypermodel.predict(test_images)\n",
    "\n",
    "# Convert predictions classes to one hot vectors\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(test_labels, Y_pred_classes)\n",
    "\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    confusion_mtx,\n",
    "    classes=classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703bec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = []\n",
    "for i in range(len(test_labels)):\n",
    "    if not Y_pred_classes[i] == test_labels[i]:\n",
    "        incorrect.append(i)\n",
    "    if len(incorrect) == 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df830269",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "fig.set_size_inches(10, 10)\n",
    "ax[0, 0].imshow(test_images[incorrect[0]].reshape(28, 28), cmap=\"gray\")\n",
    "\n",
    "ax[0, 0].set_title(\n",
    "    \"Predicted Label : \"\n",
    "    + class_names[Y_pred_classes[incorrect[0]]]\n",
    "    + \"\\n\"\n",
    "    + \"Actual Label : \"\n",
    "    + class_names[test_labels[incorrect[0]]]\n",
    ")\n",
    "ax[0, 1].imshow(test_images[incorrect[1]].reshape(28, 28), cmap=\"gray\")\n",
    "ax[0, 1].set_title(\n",
    "    \"Predicted Label : \"\n",
    "    + class_names[Y_pred_classes[incorrect[1]]]\n",
    "    + \"\\n\"\n",
    "    + \"Actual Label : \"\n",
    "    + class_names[test_labels[incorrect[1]]]\n",
    ")\n",
    "ax[1, 0].imshow(test_images[incorrect[2]].reshape(28, 28), cmap=\"gray\")\n",
    "ax[1, 0].set_title(\n",
    "    \"Predicted Label : \"\n",
    "    + class_names[Y_pred_classes[incorrect[2]]]\n",
    "    + \"\\n\"\n",
    "    + \"Actual Label : \"\n",
    "    + class_names[test_labels[incorrect[2]]]\n",
    ")\n",
    "ax[1, 1].imshow(test_images[incorrect[3]].reshape(28, 28), cmap=\"gray\")\n",
    "ax[1, 1].set_title(\n",
    "    \"Predicted Label : \"\n",
    "    + class_names[Y_pred_classes[incorrect[3]]]\n",
    "    + \"\\n\"\n",
    "    + \"Actual Label : \"\n",
    "    + class_names[test_labels[incorrect[3]]]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
